(globalThis.TURBOPACK||(globalThis.TURBOPACK=[])).push(["object"==typeof document?document.currentScript:void 0,71689,e=>{"use strict";e.s(["ArrowLeft",()=>t],71689);let t=(0,e.i(75254).default)("arrow-left",[["path",{d:"m12 19-7-7 7-7",key:"1l729n"}],["path",{d:"M19 12H5",key:"x3x0zl"}]])},25652,e=>{"use strict";e.s(["TrendingUp",()=>t],25652);let t=(0,e.i(75254).default)("trending-up",[["path",{d:"M16 7h6v6",key:"box55l"}],["path",{d:"m22 7-8.5 8.5-5-5L2 17",key:"1t1m79"}]])},31171,e=>{"use strict";e.s(["default",()=>t]);let t=(0,e.i(75254).default)("chevron-down",[["path",{d:"m6 9 6 6 6-6",key:"qrunsl"}]])},87316,68834,e=>{"use strict";e.s(["Calendar",()=>t],87316);let t=(0,e.i(75254).default)("calendar",[["path",{d:"M8 2v4",key:"1cmpym"}],["path",{d:"M16 2v4",key:"4m81vk"}],["rect",{width:"18",height:"18",x:"3",y:"4",rx:"2",key:"1hopcy"}],["path",{d:"M3 10h18",key:"8toen8"}]]);e.s(["create",()=>r],68834);var i=e.i(71645);let a=e=>{let t,i=new Set,a=(e,a)=>{let s="function"==typeof e?e(t):e;if(!Object.is(s,t)){let e=t;t=(null!=a?a:"object"!=typeof s||null===s)?s:Object.assign({},t,s),i.forEach(i=>i(t,e))}},s=()=>t,o={setState:a,getState:s,getInitialState:()=>r,subscribe:e=>(i.add(e),()=>i.delete(e))},r=t=e(a,s,o);return o},s=e=>e,o=e=>{let t=(e=>e?a(e):a)(e),o=e=>(function(e){let t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:s,a=i.default.useSyncExternalStore(e.subscribe,i.default.useCallback(()=>t(e.getState()),[e,t]),i.default.useCallback(()=>t(e.getInitialState()),[e,t]));return i.default.useDebugValue(a),a})(t,e);return Object.assign(o,t),o},r=e=>e?o(e):o},64659,63059,e=>{"use strict";e.s(["ChevronDown",()=>t.default],64659);var t=e.i(31171);e.s(["ChevronRight",()=>i],63059);let i=(0,e.i(75254).default)("chevron-right",[["path",{d:"m9 18 6-6-6-6",key:"mthhwq"}]])},39616,e=>{"use strict";e.s(["Settings",()=>t],39616);let t=(0,e.i(75254).default)("settings",[["path",{d:"M9.671 4.136a2.34 2.34 0 0 1 4.659 0 2.34 2.34 0 0 0 3.319 1.915 2.34 2.34 0 0 1 2.33 4.033 2.34 2.34 0 0 0 0 3.831 2.34 2.34 0 0 1-2.33 4.033 2.34 2.34 0 0 0-3.319 1.915 2.34 2.34 0 0 1-4.659 0 2.34 2.34 0 0 0-3.32-1.915 2.34 2.34 0 0 1-2.33-4.033 2.34 2.34 0 0 0 0-3.831A2.34 2.34 0 0 1 6.35 6.051a2.34 2.34 0 0 0 3.319-1.915",key:"1i5ecw"}],["circle",{cx:"12",cy:"12",r:"3",key:"1v7zrd"}]])},69638,e=>{"use strict";e.s(["CheckCircle",()=>t],69638);let t=(0,e.i(75254).default)("circle-check-big",[["path",{d:"M21.801 10A10 10 0 1 1 17 3.335",key:"yps3ct"}],["path",{d:"m9 11 3 3L22 4",key:"1pflzl"}]])},86630,18218,e=>{"use strict";e.s(["StepIndicator",()=>a],86630);var t=e.i(43476);let i=[{number:1,label:"Choose Template"},{number:2,label:"Select Scope"},{number:3,label:"Configure Metrics"},{number:4,label:"Customize & Save"}];function a(e){let{currentStep:a}=e;return(0,t.jsx)("div",{className:"flex justify-center",children:(0,t.jsx)("div",{className:"flex items-center space-x-8",children:i.map((e,s)=>(0,t.jsxs)("div",{className:"flex items-center",children:[(0,t.jsxs)("div",{className:"flex items-center",children:[(0,t.jsx)("div",{className:"\n                w-8 h-8 rounded-full flex items-center justify-center text-sm font-semibold\n                ".concat(e.number<=a?"bg-blue-600 text-white":"bg-gray-200 text-gray-600","\n              "),children:e.number}),(0,t.jsx)("span",{className:"ml-3 text-sm font-medium ".concat(e.number<=a?"text-blue-600":"text-gray-500"),children:e.label})]}),s<i.length-1&&(0,t.jsx)("div",{className:"ml-8 w-12 h-0.5 ".concat(e.number<a?"bg-blue-600":"bg-gray-200")})]},e.number))})})}e.s(["TEMPLATE_CONFIGS",()=>s],18218);let s=[{id:"execution_performance",name:"Test Execution Performance",description:"Analyze execution times, resource utilization, and automation efficiency. Compare manual vs automated performance across different scopes.",icon:"‚ö°",businessValue:"Performance ROI",persona:["QA Managers","Team Leads"],dataset:"test_execution_dataset",chartType:"mixed_timeseries",optimalScope:["time"],supportedScopes:["time","sprint","release"],autoConfig:{metrics:["AVG(duration)","COUNT(*)"],groupBy:["test_type","DATE_TRUNC('day', start_time)"],preFilters:[{col:"tc.status",op:"==",val:"Published"}]},level1Options:[{id:"time_scope",type:"scope",label:"Time Period",options:["Last 7 days","Last 30 days","Last 3 months","Custom range"],defaultValue:"Last 30 days"},{id:"test_type_filter",type:"filter",label:"Test Type",options:["All tests","Manual only","Automated only","Compare manual vs automated"],defaultValue:"Compare manual vs automated"},{id:"project_scope",type:"filter",label:"Project",options:"auto_populated_from_user_access",defaultValue:"current_project"}],level2Options:[{id:"additional_metrics",type:"metrics",label:"Additional Insights",options:["P95 execution time (95th percentile)","Execution efficiency (tests per hour)","Resource utilization (concurrent sessions)","Environment-specific performance"]},{id:"advanced_filters",type:"filters",label:"Advanced Filtering",options:["filter_by_who_ran_tests","filter_by_test_environment","exclude_very_short_or_long_tests","focus_on_specific_failure_patterns"]}],level3Options:[{id:"custom_time_aggregation",type:"grouping",label:"Custom Time Aggregation",description:"Control how data is grouped over time for advanced analysis",options:["Hourly (last 24 hours)","Daily (default)","Weekly (last 3 months)","Monthly (last year)","Custom intervals"],defaultValue:"Daily (default)"},{id:"performance_calculations",type:"metrics",label:"Custom Performance Calculations",description:"Advanced metrics for performance analysis",options:["Execution velocity trends (acceleration/deceleration)","Resource utilization ratios (CPU, Memory, Network)","Queue wait time vs execution time","Performance degradation detection","Outlier detection and filtering"]},{id:"cross_environment_analysis",type:"comparison",label:"Cross-Environment Comparisons",description:"Compare performance across different environments and configurations",options:["Environment performance baseline comparison","Configuration impact analysis (OS, Browser, Version)","Parallel execution efficiency","Environment stability scoring","Resource contention analysis"]},{id:"custom_thresholds",type:"analysis",label:"Performance Thresholds & Alerts",description:"Set custom performance benchmarks and alert conditions",options:["Custom duration thresholds (Fast/Medium/Slow)","Performance regression detection","Execution efficiency targets","Resource utilization alerts","SLA compliance tracking"]}],exampleQuery:"Show me average test execution time trends over the last month, comparing manual vs automated tests"},{id:"quality_trends",name:"Quality Trends & Pass Rate Analysis",description:"Track pass/fail rates, identify quality degradation patterns, and monitor test stability across time periods or iterations.",icon:"üìä",businessValue:"Quality Gate",persona:["QA Directors","Release Managers"],dataset:"test_execution_dataset",chartType:"stacked_bar_with_line",optimalScope:["sprint"],supportedScopes:["time","sprint","release"],autoConfig:{metrics:{bars:"COUNT(*) GROUP BY status",line:"(SUM(is_passed)/COUNT(*)) * 100"},groupBy:["DATE_TRUNC('day', start_time)","status"],preFilters:[{col:"tc.status",op:"==",val:"Published"}]},level1Options:[{id:"sprint_scope",type:"scope",label:"Sprint",options:"auto_populated_from_sprints",defaultValue:"current_sprint"},{id:"time_granularity",type:"grouping",label:"View By",options:["Daily","Weekly"],defaultValue:"Daily"},{id:"status_focus",type:"filter",label:"Focus On",options:["All statuses","Pass/Fail only","Failed tests only"],defaultValue:"All statuses"}],level2Options:[{id:"comparison_modes",type:"comparison",label:"Comparative Analysis",options:["compare_to_previous_sprint","compare_to_team_average","set_quality_thresholds"]}],level3Options:[{id:"statistical_analysis",type:"analysis",label:"Statistical Quality Analysis",description:"Advanced statistical methods for quality trend analysis",options:["Regression analysis (quality trend prediction)","Moving averages (3, 7, 14 day smoothing)","Quality volatility measurement","Confidence intervals for pass rates","Statistical significance testing"]},{id:"multi_period_comparison",type:"comparison",label:"Multi-Period Analysis",description:"Compare quality across multiple time periods and releases",options:["Release-over-release quality comparison","Seasonal pattern detection","Sprint velocity vs quality correlation","Long-term quality trend analysis","Quality improvement rate calculation"]},{id:"custom_quality_metrics",type:"metrics",label:"Custom Quality Calculations",description:"Define advanced quality metrics and KPIs",options:["Quality stability index (consistency over time)","Defect escape rate calculation","First-time pass rate (no retests)","Quality recovery time (time to fix)","Test effectiveness score"]},{id:"quality_forecasting",type:"analysis",label:"Quality Forecasting & Alerts",description:"Predict future quality trends and set intelligent alerts",options:["Quality trend forecasting (next 2-4 sprints)","Early warning indicators (quality degradation)","Release readiness prediction","Quality gate violation alerts","Team performance trajectory"]}],exampleQuery:"Display Sprint 7 daily pass rate trends with execution volume context"},{id:"coverage_readiness",name:"Requirement Coverage & Test Readiness",description:"Monitor test coverage percentages, identify uncovered requirements, and track testing progress against planned scope.",icon:"üéØ",businessValue:"Release Readiness",persona:["Product Managers","QA Directors"],dataset:"requirement_coverage_dataset",chartType:"progress_bars_with_breakdown",optimalScope:["sprint","release"],supportedScopes:["time","sprint","release"],autoConfig:{metrics:{test_coverage:"(COUNT(DISTINCT CASE WHEN has_published_test = 1 THEN req.id END) / COUNT(DISTINCT req.id)) * 100",execution_coverage:"(COUNT(DISTINCT CASE WHEN latest_execution_status IS NOT NULL THEN req.id END) / COUNT(DISTINCT req.id)) * 100",pass_coverage:"(COUNT(DISTINCT CASE WHEN latest_execution_status = 'Passed' THEN req.id END) / COUNT(DISTINCT req.id)) * 100"},complexLogic:!0},level1Options:[{id:"release_scope",type:"scope",label:"Release",options:"auto_populated_from_releases",defaultValue:"active_release"},{id:"coverage_type",type:"filter",label:"Coverage Type",options:["All coverage types","Test coverage only","Execution coverage only"],defaultValue:"All coverage types"},{id:"priority_filter",type:"filter",label:"Priority",options:["All priorities","High priority only","Critical only"],defaultValue:"All priorities"}],level2Options:[{id:"coverage_breakdown",type:"grouping",label:"Breakdown By",options:["By component","By feature","By priority","By assignee"]}],level3Options:[{id:"coverage_formulas",type:"metrics",label:"Advanced Coverage Calculations",description:"Custom coverage metrics and formulas for detailed analysis",options:["Weighted coverage by priority (Critical=3x, High=2x)","Risk-adjusted coverage (coverage * complexity)","Test completeness index (coverage + execution + pass)","Coverage velocity tracking (rate of improvement)","Gap analysis scoring (uncovered risk assessment)"]},{id:"cross_release_analysis",type:"comparison",label:"Multi-Release Comparisons",description:"Compare coverage across releases and track progress",options:["Release-over-release coverage comparison","Coverage consistency analysis","Requirement stability tracking","Testing maturity progression","Coverage debt analysis (accumulated gaps)"]},{id:"requirement_intelligence",type:"analysis",label:"Requirement Intelligence",description:"Advanced analysis of requirement coverage patterns",options:["High-risk uncovered requirements","Test case effectiveness per requirement","Requirements change impact analysis","Coverage pattern recognition","Testing bottleneck identification"]},{id:"readiness_forecasting",type:"analysis",label:"Release Readiness Prediction",description:"Predict and track release readiness based on coverage trends",options:["Coverage completion forecasting","Release readiness scoring","Testing timeline estimation","Risk-based readiness assessment","Go/No-Go decision support metrics"]}],exampleQuery:"What percentage of Release 2.1 requirements are fully tested and passing?"},{id:"defect_intelligence",name:"Defect Intelligence & Resolution Analysis",description:"Analyze defect creation vs resolution trends, track resolution times, and identify quality hotspots by priority and component.",icon:"üêõ",businessValue:"Quality Intelligence",persona:["QA Managers","Development Leads"],dataset:"defect_analysis_dataset",chartType:"dual_axis_combo",optimalScope:["time"],supportedScopes:["time","sprint","release"],autoConfig:{metrics:{creation_rate:"COUNT(*) WHERE created_date",resolution_rate:"COUNT(*) WHERE resolved_date IS NOT NULL",avg_resolution_time:"AVG(resolved_date - created_date)",open_critical:"COUNT(*) WHERE is_open = 1 AND is_blocking = 1"},groupBy:["DATE_TRUNC('week', created_date)","priority"]},level1Options:[{id:"time_range",type:"scope",label:"Time Range",options:["Last month","Last 3 months","Last 6 months"],defaultValue:"Last 3 months"},{id:"priority_focus",type:"filter",label:"Priority",options:["All priorities","Critical & High","Critical only"],defaultValue:"All priorities"},{id:"status_filter",type:"filter",label:"Status",options:["All defects","Open defects","Resolved defects"],defaultValue:"Open defects"}],level2Options:[{id:"resolution_analysis",type:"metrics",label:"Resolution Analysis",options:["Average resolution time by priority","Resolution velocity trends","Backlog growth analysis"]}],exampleQuery:"Track critical defect resolution time trends and identify if we're keeping up with defect discovery"},{id:"testcase_productivity",name:"Test Case Activity & Team Productivity",description:"Monitor test case creation, modification activity, and automation transition progress. Track team productivity and identify bottlenecks.",icon:"üìù",businessValue:"Team Efficiency",persona:["Team Leads","QA Managers"],dataset:"test_case_management_dataset",chartType:"activity_timeline",optimalScope:["time"],supportedScopes:["time","sprint","release"],autoConfig:{metrics:{creation_count:"COUNT(*) WHERE created_date",modification_count:"COUNT(*) WHERE updated_date > created_date",automation_rate:"(COUNT(CASE WHEN type IN ('Automated', 'Manual & Automated') THEN 1 END) / COUNT(*)) * 100"},groupBy:["author","DATE_TRUNC('week', updated_date)"]},level1Options:[{id:"time_period",type:"scope",label:"Time Period",options:["Last sprint","Last month","Last quarter"],defaultValue:"Last sprint"},{id:"activity_type",type:"filter",label:"Activity Type",options:["All activities","Creation only","Updates only","Automation changes"],defaultValue:"All activities"},{id:"team_scope",type:"filter",label:"Team",options:"auto_populated_from_teams",defaultValue:"current_team"}],level2Options:[{id:"productivity_metrics",type:"metrics",label:"Productivity Metrics",options:["Test cases per author per week","Automation conversion rate","Review cycle time"]}],exampleQuery:"Show test case creation activity by team member over the last sprint with automation adoption rates"},{id:"cross_entity_analysis",name:"Cross-Entity Quality Intelligence",description:"Advanced analysis combining test execution, coverage, and defects. Identify relationships between coverage gaps, test failures, and defect patterns.",icon:"üîó",businessValue:"Strategic Insight",persona:["QA Directors","Engineering Managers"],dataset:"requirement_coverage_dataset",datasets:["requirement_coverage_dataset","defect_analysis_dataset","test_execution_dataset"],chartType:"bubble_matrix",optimalScope:["sprint","release"],supportedScopes:["time","sprint","release"],autoConfig:{joinStrategy:"requirement_based",metrics:{coverage_percent:"FROM requirement_coverage_dataset",defect_density:"FROM defect_analysis_dataset",test_volume:"FROM test_execution_dataset"}},level1Options:[{id:"analysis_scope",type:"scope",label:"Analysis Scope",options:["Current sprint","Current release","Last completed sprint"],defaultValue:"Current sprint"},{id:"entity_focus",type:"filter",label:"Focus On",options:["All components","High-risk areas","Low coverage areas"],defaultValue:"All components"}],level2Options:[{id:"correlation_analysis",type:"analysis",label:"Correlation Analysis",options:["Coverage vs Defect Density","Test Volume vs Quality","Team Performance vs Coverage"]}],exampleQuery:"Show correlation between requirement coverage levels and defect discovery rates by component"},{id:"operational_health",name:"Test Infrastructure & Resource Health",description:"Monitor testing infrastructure utilization, concurrent execution patterns, and environment-specific performance characteristics.",icon:"üíä",businessValue:"Operations",persona:["DevOps Engineers","QA Infrastructure"],dataset:"test_execution_dataset",chartType:"gauge_and_heatmap",optimalScope:["time"],supportedScopes:["time","sprint","release"],autoConfig:{metrics:{concurrency:"COUNT(DISTINCT session_id)",resource_utilization:"AVG(concurrent_sessions)",environment_performance:"AVG(duration) GROUP BY environment"},refreshRate:"5_minutes"},level1Options:[{id:"monitoring_period",type:"scope",label:"Monitoring Period",options:["Last 24 hours","Last 7 days","Real-time"],defaultValue:"Last 24 hours"},{id:"environment_filter",type:"filter",label:"Environment",options:["All environments","QA only","Staging only","Production only"],defaultValue:"All environments"}],level2Options:[{id:"operational_metrics",type:"metrics",label:"Operational Metrics",options:["Peak usage times","Resource bottlenecks","Environment reliability"]}],exampleQuery:"Display testing infrastructure load patterns and identify peak usage times across different environments"},{id:"configuration_matrix",name:"Configuration Coverage Matrix",description:"Advanced platform coverage analysis showing test execution distribution across OS, browser, and device combinations with gap identification.",icon:"üåê",businessValue:"Coverage Matrix",persona:["QA Leads","Cross-platform Teams"],dataset:"test_execution_dataset",chartType:"matrix_heatmap",optimalScope:["sprint","release"],supportedScopes:["time","sprint","release"],autoConfig:{dimensions:["os","browser","browser_version"],metrics:["COUNT(DISTINCT test_case_id)"],visualization:{colorScale:"sequential",showMissing:!0}},level1Options:[{id:"coverage_scope",type:"scope",label:"Coverage Scope",options:["Current sprint","Current release","Last 30 days"],defaultValue:"Current sprint"},{id:"platform_focus",type:"filter",label:"Platform Focus",options:["All platforms","Desktop only","Mobile only","Cross-platform"],defaultValue:"All platforms"}],level2Options:[{id:"matrix_dimensions",type:"dimensions",label:"Matrix Dimensions",options:["OS + Browser + Version","Device + OS + Browser","Environment + Configuration"]}],exampleQuery:"Show comprehensive test coverage matrix across all platform configurations for Release 2.1"}]}]);